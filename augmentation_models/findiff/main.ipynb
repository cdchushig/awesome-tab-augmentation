{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install required libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required libraries\n",
    "!pip install sdv # install the synthetic data vault library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# import scikit-learn preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, QuantileTransformer\n",
    "\n",
    "# import pytorch libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# import synthetic data vault libraries\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "import sdv.evaluation.single_table as sdv_st\n",
    "\n",
    "# import utility libraries\n",
    "from tqdm import tqdm\n",
    "import xlrd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from datetime import datetime\n",
    "\n",
    "# import visualisation libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init and set experiment parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "seed = 1234\n",
    "\n",
    "# set dimension of categorical embeddings\n",
    "cat_emb_dim = 2\n",
    "\n",
    "# set number of neurons per layer\n",
    "mlp_layers = [1024, 1024, 1024, 1024]\n",
    "\n",
    "# set non-linear activation function\n",
    "activation = 'lrelu'\n",
    "\n",
    "# set number of diffusion steps\n",
    "diffusion_steps = 500\n",
    "\n",
    "# set diffusion start and end betas\n",
    "diffusion_beta_start = 1e-4\n",
    "diffusion_beta_end = 0.02\n",
    "\n",
    "# set diffusion scheduler\n",
    "scheduler = 'linear'\n",
    "\n",
    "# set number of training epochs\n",
    "epochs = 500\n",
    "\n",
    "# set training batch size\n",
    "batch_size = 512\n",
    "\n",
    "# set training learning rate\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# set the device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\").type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set numpy seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "# set pytorch seed\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# set cuda seed\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, pre-process, and init the UCU Credit Card dataset\n",
    "The dataset is available under https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data path\n",
    "data_url = 'https://archive.ics.uci.edu/static/public/350/default+of+credit+card+clients.zip'\n",
    "\n",
    "# download the file\n",
    "response = requests.get(data_url)\n",
    "\n",
    "# determine the zip file\n",
    "zip_file = ZipFile(BytesIO(response.content))\n",
    "\n",
    "# extract the zip file\n",
    "zip_file.extractall('data')\n",
    "\n",
    "# read the UCI credit card dataset\n",
    "train_raw = pd.read_excel('data/default of credit card clients.xls', skiprows=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the top 10 rows and attribute names of the dataset retreived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display top 10 rows\n",
    "train_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display attribute names \n",
    "train_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set numerical and categorical dataset attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine categorical attributes\n",
    "cat_attrs = ['SEX', 'EDUCATION', 'MARRIAGE', 'AGE', 'PAY0', 'PAY2', 'PAY3', 'PAY4', 'PAY5', 'PAY6']\n",
    "\n",
    "# determine numerical attributes\n",
    "num_attrs = ['LIMITBAL', 'BILLAMT1', 'BILLAMT2', 'BILLAMT3', 'BILLAMT4', 'BILLAMT5', 'BILLAMT6',\n",
    "             'PAYAMT1', 'PAYAMT2', 'PAYAMT3', 'PAYAMT4', 'PAYAMT5', 'PAYAMT6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process dataset attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove underscore in column names for correct inverse decoding\n",
    "train_raw.columns = [col.replace('_', '') for col in train_raw.columns]\n",
    "\n",
    "# convert categorical attributes to string\n",
    "train_raw[cat_attrs] = train_raw[cat_attrs].astype(str)\n",
    "\n",
    "# iterate over categorical attributes\n",
    "for cat_attr in cat_attrs:\n",
    "\n",
    "    # add col name to every categorical entry to make them distinguishable for embedding\n",
    "    train_raw[cat_attr] = cat_attr + '_' + train_raw[cat_attr].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set dataset label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract label\n",
    "label = train_raw['default payment next month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge selected categorical and numerical attributes\n",
    "train = train_raw[[*cat_attrs, *num_attrs]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the numerical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the quantile transformation\n",
    "num_scaler = QuantileTransformer(output_distribution='normal', random_state=seed)\n",
    "\n",
    "# fit transformation to numerical attributes\n",
    "num_scaler.fit(train[num_attrs])\n",
    "\n",
    "# transform numerical attributes\n",
    "train_num_scaled = num_scaler.transform(train[num_attrs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the categorical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocabulary of categorical attributes\n",
    "vocabulary_classes = np.unique(train[cat_attrs])\n",
    "\n",
    "# init categorical attribute encoder \n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# fit encoder to categorical attributes\n",
    "label_encoder.fit(vocabulary_classes)\n",
    "\n",
    "# transform categorical attributes\n",
    "train_cat_scaled = train[cat_attrs].apply(label_encoder.transform)\n",
    "\n",
    "# collect unique values of each categorical attribute\n",
    "vocab_per_attr = {cat_attr: set(train_cat_scaled[cat_attr]) for cat_attr in cat_attrs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert numerical and categorical attributes as well as the labels to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numerical attributes\n",
    "train_num_torch = torch.FloatTensor(train_num_scaled)\n",
    "\n",
    "# convert categorical attributes\n",
    "train_cat_torch = torch.LongTensor(train_cat_scaled.values)\n",
    "\n",
    "# convert label\n",
    "label_torch = torch.LongTensor(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataset to tensor dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init tensor dataset\n",
    "train_set = TensorDataset(\n",
    "    train_cat_torch, # categorical attributes\n",
    "    train_num_torch, # numerical attributes\n",
    "    label_torch # dataset labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init the data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the data loader\n",
    "dataloader = DataLoader(\n",
    "    dataset=train_set, # training dataset\n",
    "    batch_size=batch_size, # training batch size\n",
    "    num_workers=0, # number of workers\n",
    "    shuffle=True # shuffle training data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the FinDiff model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the FinDiff backbone model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base feedforward network\n",
    "class BaseNetwork(nn.Module):\n",
    "\n",
    "    # define base network constructor\n",
    "    def __init__(self, hidden_size, activation='lrelu'):\n",
    "\n",
    "        # call super calass constructor \n",
    "        super(BaseNetwork, self).__init__()\n",
    "\n",
    "        # init \n",
    "        self.layers = self.init_layers(hidden_size)\n",
    "\n",
    "        # case: lrelu activation\n",
    "        if activation == 'lrelu':\n",
    "\n",
    "            # set lrelu activation\n",
    "            self.activation = nn.LeakyReLU(negative_slope=0.4, inplace=True)\n",
    "\n",
    "        # case: relu activation\n",
    "        elif activation == 'relu':\n",
    "\n",
    "            # set relu activation\n",
    "            self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "        # case: tanh activation\n",
    "        elif activation == 'tanh':\n",
    "\n",
    "            # set tanh activation\n",
    "            self.activation = nn.Tanh()\n",
    "\n",
    "        # case: sigmoid activation\n",
    "        else:\n",
    "\n",
    "            # set sigmoid activation\n",
    "            self.activation = nn.Sigmoid()\n",
    "\n",
    "    # define layer initialization \n",
    "    def init_layers(self, layer_dimensions):\n",
    "\n",
    "        # init layers\n",
    "        layers = []\n",
    "\n",
    "        # iterate over layer dimensions \n",
    "        for i in range(len(layer_dimensions)-1):\n",
    "\n",
    "            # init linear layer \n",
    "            layer = nn.Linear(layer_dimensions[i], layer_dimensions[i + 1], bias=True)\n",
    "            \n",
    "            # init linear layer weights\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "            \n",
    "            # init linear layer bias\n",
    "            nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "            # collecet linear layer \n",
    "            layers.append(layer)\n",
    "            \n",
    "            # register linear layer parameters\n",
    "            self.add_module('linear_' + str(i), layer)\n",
    "\n",
    "        # return layers\n",
    "        return layers\n",
    "\n",
    "    # define forward pass\n",
    "    def forward(self, x):\n",
    "\n",
    "        # iterate over layers\n",
    "        for i in range(len(self.layers)):\n",
    "\n",
    "            # run layer forward pass \n",
    "            x = self.activation(self.layers[i](x))\n",
    "\n",
    "        # return forward pass result\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the FinDiff model synthesizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define MLP synthesizer network\n",
    "class MLPSynthesizer(nn.Module):\n",
    "\n",
    "    # define MLP synthesizer network constructor\n",
    "    def __init__(\n",
    "            self, \n",
    "            d_in: int, \n",
    "            hidden_layers: list, \n",
    "            activation: str='lrelu', # layer activation \n",
    "            dim_t: int=64, \n",
    "            n_cat_tokens=None, # number of categorical tokens\n",
    "            n_cat_emb=None, # number of categorical dimensions\n",
    "            embedding=None, \n",
    "            embedding_learned=True, \n",
    "            n_classes=None\n",
    "        ):\n",
    "\n",
    "        # call super class constructor\n",
    "        super(MLPSynthesizer, self).__init__()\n",
    "\n",
    "        # init ??? \n",
    "        self.dim_t = dim_t\n",
    "\n",
    "        # init synthesizer base feed forward network\n",
    "        self.backbone = BaseNetwork([dim_t, *hidden_layers], activation=activation)\n",
    "        \n",
    "        # case: categorical embedding defined\n",
    "        if embedding is not None:\n",
    "\n",
    "            # init pretrained embedding layer \n",
    "            self.cat_embedding = nn.Embedding.from_pretrained(embeddings=embedding)\n",
    "\n",
    "        # case: categorical embedding undefined \n",
    "        else:\n",
    "\n",
    "            # init new categorical embedding layer \n",
    "            self.cat_embedding = nn.Embedding(n_cat_tokens, n_cat_emb, max_norm=None, scale_grad_by_freq=False)\n",
    "\n",
    "            # activate categorical embedding layer learning\n",
    "            self.cat_embedding.weight.requires_grad = embedding_learned\n",
    "\n",
    "        # case: data classes available\n",
    "        if n_classes is not None:\n",
    "\n",
    "            # init label embedding layer \n",
    "            self.label_embedding = nn.Embedding(n_classes, dim_t)\n",
    "\n",
    "        # define input data projection\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(d_in, dim_t), # linear layer \n",
    "            nn.SiLU(), # silu activation\n",
    "            nn.Linear(dim_t, dim_t) # linear layer \n",
    "        )\n",
    "        \n",
    "        # define time embedding projection\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(dim_t, dim_t), # linear layer \n",
    "            nn.SiLU(), # silu activation\n",
    "            nn.Linear(dim_t, dim_t) # linear layer \n",
    "        )\n",
    "        \n",
    "        # define output data projection\n",
    "        self.head = nn.Linear(hidden_layers[-1], d_in)\n",
    "\n",
    "    # define sinusodial time step embedding\n",
    "    def embed_time(self, timesteps, dim_out, max_period=10000):\n",
    "\n",
    "        # half output dimension\n",
    "        half_dim_out = dim_out // 2\n",
    "\n",
    "        # determine tensor of frequencies\n",
    "        freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half_dim_out, dtype=torch.float32) / half_dim_out)\n",
    "\n",
    "        # push to compute device\n",
    "        freqs = freqs.to(device=timesteps.device)\n",
    "        \n",
    "        # create timestep vs. frequency grid\n",
    "        args = timesteps[:, None].float() * freqs[None]\n",
    "\n",
    "        # creating the time embedding \n",
    "        time_embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "\n",
    "        # case: odd output dimension\n",
    "        if dim_out % 2:\n",
    "\n",
    "            # append additional dimension\n",
    "            time_embedding = torch.cat([time_embedding, torch.zeros_like(time_embedding[:, :1])], dim=-1)\n",
    "\n",
    "        # return timestep embedding\n",
    "        return time_embedding\n",
    "\n",
    "    # get categorical embeddings\n",
    "    def get_embeddings(self):\n",
    "\n",
    "        # return categorical embeddings\n",
    "        return self.cat_embedding.weight.data\n",
    "\n",
    "    # perform categorical embedding\n",
    "    def embed_categorical(self, x_cat):\n",
    "\n",
    "        # perform categorical embedding\n",
    "        x_cat_emb = self.cat_embedding(x_cat)\n",
    "\n",
    "        # reshape embedding to original input\n",
    "        x_cat_emb = x_cat_emb.view(-1, x_cat_emb.shape[1] * x_cat_emb.shape[2])\n",
    "\n",
    "        # return categorical embedding\n",
    "        return x_cat_emb\n",
    "\n",
    "    # define forward pass\n",
    "    def forward(self, x, timesteps, label=None):\n",
    "        \n",
    "        # init time embeddings\n",
    "        time_emb = self.embed_time(timesteps, self.dim_t)\n",
    "\n",
    "        # embedd time embeddings\n",
    "        time_emb  = self.time_embed(time_emb )\n",
    "        \n",
    "        # case: data classes available\n",
    "        if label is not None:\n",
    "\n",
    "            # determine label embeddings\n",
    "            time_label_emb = time_emb  + self.label_embedding(label)\n",
    "\n",
    "        # run initial projection layer \n",
    "        x = self.projection(x) \n",
    "        \n",
    "        # add time and label embedding \n",
    "        x = x + time_label_emb\n",
    "\n",
    "        # run backbone forward pass\n",
    "        x =  self.backbone(x)\n",
    "\n",
    "        # run projection forward pass\n",
    "        x = self.head(x)\n",
    "\n",
    "        # return forward pass result\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the FinDiff model base diffuser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define BaseDiffuser network\n",
    "class BaseDiffuser(object):\n",
    "\n",
    "    # define base diffuser network constructor\n",
    "    def __init__(\n",
    "            self, \n",
    "            total_steps=1000, \n",
    "            beta_start=1e-4, \n",
    "            beta_end=0.02, \n",
    "            device='cpu',\n",
    "            scheduler='linear'\n",
    "        ):\n",
    "\n",
    "        # set diffusion steps\n",
    "        self.total_steps = total_steps\n",
    "\n",
    "        # set diffusion start beta\n",
    "        self.beta_start = beta_start\n",
    "\n",
    "        # set diffusion end beta\n",
    "        self.beta_end = beta_end\n",
    "\n",
    "        # set compute device\n",
    "        self.device = device\n",
    "\n",
    "        # set noise schedule alphas and betas\n",
    "        self.alphas, self.betas = self.prepare_noise_schedule(scheduler=scheduler)\n",
    "\n",
    "        # set noise schedule alhpa hats\n",
    "        self.alphas_hat = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "    # define noise schedule\n",
    "    def prepare_noise_schedule(self, scheduler: str):\n",
    "\n",
    "        # determine noise scheduler scale\n",
    "        scale = 1000 / self.total_steps\n",
    "\n",
    "        # scale beta start\n",
    "        beta_start = scale * self.beta_start\n",
    "\n",
    "        # scale beta end\n",
    "        beta_end = scale * self.beta_end\n",
    "\n",
    "        # case: linear noise scheduler\n",
    "        if scheduler == 'linear':\n",
    "\n",
    "            # determine linear noise schedule betas\n",
    "            betas = torch.linspace(beta_start, beta_end, self.total_steps)\n",
    "\n",
    "            # determine linear noise schedule alphas\n",
    "            alphas = 1.0 - betas\n",
    "\n",
    "        # case: quadratic noise scheduler\n",
    "        elif scheduler == 'quad':\n",
    "\n",
    "            # determine quadratic noise schedule betas\n",
    "            betas = torch.linspace(self.beta_start ** 0.5, self.beta_end ** 0.5, self.total_steps) ** 2\n",
    "\n",
    "            # determine quadratic noise schedule alphas \n",
    "            alphas = 1.0 - betas\n",
    "\n",
    "        # return noise scheduler alphas and betas\n",
    "        return alphas.to(self.device), betas.to(self.device)\n",
    "\n",
    "    # define random timesteps sampler \n",
    "    def sample_random_timesteps(self, n: int):\n",
    "\n",
    "        # sample random timesteps\n",
    "        t = torch.randint(low=1, high=self.total_steps, size=(n,), device=self.device)\n",
    "\n",
    "        # return random timesteps\n",
    "        return t\n",
    "\n",
    "    # define gaussian noise addition\n",
    "    def add_gauss_noise(self, x_num, t):\n",
    "\n",
    "        # determine noise alpha hat\n",
    "        sqrt_alpha_hat = torch.sqrt(self.alphas_hat[t])[:, None]\n",
    "\n",
    "        # determine noise one minius alpha hat \n",
    "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alphas_hat[t])[:, None]\n",
    "\n",
    "        # determine numeric noise\n",
    "        noise_num = torch.randn_like(x_num)\n",
    "\n",
    "        # determine x numeric noise\n",
    "        x_noise_num = sqrt_alpha_hat * x_num + sqrt_one_minus_alpha_hat * noise_num\n",
    "\n",
    "        # return x numeric noise and numeric noise\n",
    "        return x_noise_num, noise_num\n",
    "\n",
    "    # define gaussian noise sampling\n",
    "    def p_sample_gauss(self, model_out, z_norm, timesteps):\n",
    "\n",
    "        # determine noise alpha hat\n",
    "        sqrt_alpha_t = torch.sqrt(self.alphas[timesteps])[:, None]\n",
    "\n",
    "        # determine noise betas\n",
    "        betas_t = self.betas[timesteps][:, None]\n",
    "        \n",
    "        # determine noise one minius alpha hat \n",
    "        sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - self.alphas_hat[timesteps])[:, None]\n",
    "        \n",
    "        epsilon_t = torch.sqrt(self.betas[timesteps][:, None])\n",
    "\n",
    "        # determine random noise\n",
    "        random_noise = torch.randn_like(z_norm)\n",
    "        random_noise[timesteps == 0] = 0.0\n",
    "\n",
    "        # determine model mean\n",
    "        model_mean = ((1 / sqrt_alpha_t) * (z_norm - (betas_t * model_out / sqrt_one_minus_alpha_hat_t)))\n",
    "\n",
    "        # determine z norm\n",
    "        z_norm = model_mean + (epsilon_t * random_noise)\n",
    "\n",
    "        # return z norm\n",
    "        return z_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and train the FinDiff model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine number unique categorical tokens\n",
    "n_cat_tokens = len(np.unique(train[cat_attrs]))\n",
    "\n",
    "# determine total categorical embedding dimension\n",
    "cat_dim = cat_emb_dim * len(cat_attrs)\n",
    "\n",
    "# determine total numerical embedding dimension\n",
    "num_dim = len(num_attrs)\n",
    "\n",
    "# determine total embedding dimension\n",
    "encoded_dim = cat_dim + num_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the FinDiff synthesizer model \n",
    "synthesizer_model = MLPSynthesizer(\n",
    "    d_in=encoded_dim,\n",
    "    hidden_layers=mlp_layers,\n",
    "    activation=activation,\n",
    "    n_cat_tokens=n_cat_tokens,\n",
    "    n_cat_emb=cat_emb_dim,\n",
    "    n_classes=pd.Series(label).nunique(),\n",
    "    embedding_learned=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the FinDiff base diffuser model\n",
    "diffuser_model = BaseDiffuser(\n",
    "    total_steps=diffusion_steps,\n",
    "    beta_start=diffusion_beta_start,\n",
    "    beta_end=diffusion_beta_end,\n",
    "    scheduler=scheduler,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init optimizer, scheduler and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine synthesizer model parameters\n",
    "parameters = filter(lambda p: p.requires_grad, synthesizer_model.parameters())\n",
    "\n",
    "# init Adam optimizer\n",
    "optimizer = optim.Adam(parameters, lr=learning_rate)\n",
    "\n",
    "# init learning rate scheduler\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=epochs, verbose=False)\n",
    "\n",
    "# int mean-squared-error loss\n",
    "loss_fnc = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init collection of training epoch losses\n",
    "train_epoch_losses = []\n",
    "\n",
    "# set the model in training mode\n",
    "synthesizer_model.train()\n",
    "\n",
    "# move to the device\n",
    "synthesizer_model = synthesizer_model.to(device)\n",
    "\n",
    "# init the training progress bar \n",
    "pbar = tqdm(iterable=range(epochs), position=0, leave=True)\n",
    "\n",
    "# iterate over training epochs\n",
    "for epoch in pbar:\n",
    "\n",
    "    base_params = {'epoch': epoch, 'seed': seed, 'mlp_layers': mlp_layers}\n",
    "\n",
    "    # init epoch training batch losses\n",
    "    batch_losses = []\n",
    "\n",
    "    # iterate over epoch batches\n",
    "    for batch_cat, batch_num, batch_y in dataloader:\n",
    "\n",
    "        # move tensors to device\n",
    "        batch_cat = batch_cat.to(device)\n",
    "        batch_num = batch_num.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        # sample diffusion timestep\n",
    "        timesteps = diffuser_model.sample_random_timesteps(n=batch_cat.shape[0])\n",
    "\n",
    "        # determine categorical embeddings\n",
    "        batch_cat_emb = synthesizer_model.embed_categorical(x_cat=batch_cat)\n",
    "\n",
    "        # concatenate categorical and numerical embeddings\n",
    "        batch_cat_num = torch.cat((batch_cat_emb, batch_num), dim=1)\n",
    "\n",
    "        # add diffuser gaussian noise\n",
    "        batch_noise_t, noise_t = diffuser_model.add_gauss_noise(x_num=batch_cat_num, t=timesteps)\n",
    "\n",
    "        # conduct synthesizer model forward pass\n",
    "        predicted_noise = synthesizer_model(x=batch_noise_t, timesteps=timesteps, label=batch_y)\n",
    "\n",
    "        # compute training batch loss\n",
    "        batch_loss = loss_fnc(input=noise_t, target=predicted_noise)\n",
    "\n",
    "        # reset model gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # run model backward pass\n",
    "        batch_loss.backward()\n",
    "\n",
    "        # optimize model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # collect training batch losses\n",
    "        batch_losses.append(batch_loss.detach().cpu().numpy())\n",
    "\n",
    "    # determine mean training epoch loss\n",
    "    batch_losses_mean = np.mean(np.array(batch_losses))\n",
    "\n",
    "    # update learning rate scheduler\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # collect mean training epoch loss\n",
    "    train_epoch_losses.append(batch_losses_mean)\n",
    "\n",
    "    # prepare and set training epoch progress bar update\n",
    "    now = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    pbar.set_description('[LOG {}] epoch: {}, train-loss: {}'.format(str(now), str(epoch).zfill(4), str(batch_losses_mean)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize training loss progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# add grid\n",
    "ax.grid(linestyle='dotted')\n",
    "\n",
    "# plot the training epochs vs. the epochs' classification error\n",
    "ax.plot(np.array(range(1, len(train_epoch_losses)+1)), train_epoch_losses, label='epoch loss (blue)')\n",
    "\n",
    "# add axis legends\n",
    "ax.set_xlabel('[Training Epoch $e_i$]', fontsize=10)\n",
    "ax.set_ylabel('[MSE Error $\\mathcal{L}^{MSE}$]', fontsize=10)\n",
    "\n",
    "# set plot legend\n",
    "plt.legend(loc='upper right', numpoints=1, fancybox=True)\n",
    "\n",
    "# add plot title\n",
    "plt.title('FinDiff Training Epochs $e_i$ vs. MSE Error $L^{MSE}$', fontsize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data using the FinDiff model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init and set sampling parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use FinDiff to generate new data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init samples to be generated\n",
    "samples = torch.randn((len(label_torch), encoded_dim), device=device)\n",
    "\n",
    "# init the generation progress bar\n",
    "pbar = tqdm(iterable=reversed(range(0, diffusion_steps)), position=0, leave=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "  # iterate over diffusion steps\n",
    "  for diffusion_step in pbar:\n",
    "\n",
    "      # prepare and set training epoch progress bar update\n",
    "      now = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
    "      pbar.set_description('[LOG {}] Diffusion Step: {}'.format(str(now), str(diffusion_step).zfill(4)))\n",
    "\n",
    "      # init diffusion timesteps\n",
    "      timesteps = torch.full((len(label_torch),), diffusion_step, dtype=torch.long, device=device)\n",
    "\n",
    "      # run synthesizer model forward pass\n",
    "      model_out = synthesizer_model(x=samples.float(), timesteps=timesteps, label=label_torch.to(device))\n",
    "\n",
    "      # run diffuser model forward pass\n",
    "      samples = diffuser_model.p_sample_gauss(model_out, samples, timesteps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decode generated FinDiff samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split sample into numeric and categorical parts\n",
    "samples = samples.detach().cpu().numpy()\n",
    "samples_num = samples[:, cat_dim:]\n",
    "samples_cat = samples[:, :cat_dim]\n",
    "\n",
    "# denormalize numeric attributes\n",
    "z_norm_upscaled = num_scaler.inverse_transform(samples_num)\n",
    "z_norm_df = pd.DataFrame(z_norm_upscaled, columns=num_attrs)\n",
    "\n",
    "# get embedding lookup matrix\n",
    "embedding_lookup = synthesizer_model.get_embeddings().cpu()\n",
    "\n",
    "# reshape back to batch_size * n_dim_cat * cat_emb_dim\n",
    "samples_cat = samples_cat.reshape(-1, len(cat_attrs), cat_emb_dim)\n",
    "\n",
    "# compute pairwise distances\n",
    "distances = torch.cdist(x1=embedding_lookup, x2=torch.Tensor(samples_cat))\n",
    "\n",
    "# get the closest distance based on the embeddings that belong to a column category\n",
    "z_cat_df = pd.DataFrame(index=range(len(samples_cat)), columns=cat_attrs)\n",
    "\n",
    "nearest_dist_df = pd.DataFrame(index=range(len(samples_cat)), columns=cat_attrs)\n",
    "\n",
    "# iterate over categorical attributes\n",
    "for attr_idx, attr_name in enumerate(cat_attrs):\n",
    "\n",
    "    attr_emb_idx = list(vocab_per_attr[attr_name])\n",
    "    attr_distances = distances[:, attr_emb_idx, attr_idx]\n",
    "\n",
    "    nearest_values, nearest_idx = torch.min(attr_distances, dim=1)\n",
    "    nearest_idx = nearest_idx.cpu().numpy()\n",
    "\n",
    "    z_cat_df[attr_name] = np.array(attr_emb_idx)[nearest_idx]  # need to map emb indices back to column indices\n",
    "    nearest_dist_df[attr_name] = nearest_values.cpu().numpy()\n",
    "\n",
    "z_cat_df = z_cat_df.apply(label_encoder.inverse_transform)\n",
    "\n",
    "samples_decoded = pd.concat([z_cat_df, z_norm_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_decoded.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a metadata for evaluation (from SDV)\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=train)\n",
    "\n",
    "# generate quality report\n",
    "quality_report = sdv_st.evaluate_quality(\n",
    "    real_data=train,\n",
    "    synthetic_data=samples_decoded,\n",
    "    metadata=metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Column Shapes -> referred to the \"Fidelity Column\" in the paper\n",
    "fig = quality_report.get_visualization(property_name='Column Shapes')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Column Pair Trends -> referred to the \"Fidelity Row\" in the paper\n",
    "fig = quality_report.get_visualization(property_name='Column Pair Trends')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
